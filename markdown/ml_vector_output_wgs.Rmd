---
title: "Lab book: ML outputs (vector), whole genome sequences"
output: radix::radix_article
geometry: margin=1in, includeheadfoot
fig_captions: true
fontsize: 3pt
header-includes:
   - \usepackage{longtable}
   - \usepackage{fancyhdr}
   - \fancyfoot[LE,RO]{\thepage}
author:
  - name: Liam Brierley
    affiliation: University of Liverpool
date: '`r format(Sys.Date(), "%Y-%m-%d")`'
---
\pagenumbering{arabic}

```{r global_options, include=FALSE}
library(caret)
library(e1071)
library(matrixStats)
library(patchwork)
library(pROC)
library(randomForest)

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, error=TRUE)

custom_kable <- function(x, caption=NULL) {
   kable(x, caption=caption) %>% kable_styling(font_size = 4, bootstrap_options = c("striped", "hover", "condensed", "responsive"), fixed_thead = T)
}

# Load in previous ML results
load("C:\\Users\\Liam\\Desktop\\CoV Genomics\\listresults_ml_vector_wg_17_07_20.RData")

# Raw probability of outcome classes
vector_probs <- prop.table(table(model_df$outcome))

# Select holdout used
# As model data
holdout_used <- lapply(unique(model_df$taxid), function(x)
   model_df %>% filter(taxid == x)
)

# # All sequences
# holdout_used <- lapply(unique(model_df$taxid), function(x)
#   model_df_predownsample %>% filter(outcome %in% unique(model_df$outcome) & taxid == x)
# )
# 
# # Minimal sequences
# set.seed(141)
# holdout_used <- lapply(unique(model_df$taxid), function(x)
#   model_df_predownsample %>% filter(outcome %in% unique(model_df$outcome) & taxid == x) %>% group_by(outcome) %>% sample_n(1)
# )
```

**Summary of host group data represented:**

```{r}
model_df_predownsample %>% 
   group_by(outcome) %>% 
   summarise(n_sequences = n(), n_species = n_distinct(taxid)) %>% 
   arrange(-n_sequences) %>%
   kable(caption = "CoV spike sequences, CoV species represented per host group before downsampling")

model_df %>% 
   group_by(outcome) %>% 
   summarise(n_sequences = n(), n_species = n_distinct(taxid)) %>% 
   arrange(-n_sequences) %>%
   kable(caption = "CoV spike sequences, CoV species represented per host group after downsampling (modelled data)")

round(prop.table(table(model_df$outcome)),3) %>% t %>%
   kable(caption = "Raw probabilities of host group")

model_df_predownsample %>% 
   filter(accessionversion %in% model_df$accessionversion) %>% 
   summarise_at(c("class_name","order_name","family_name","genus_name","species_name"), n_distinct, na.rm = TRUE) %>% 
   kable(caption = "n host taxonomic levels represented total among modelled data")
```

**Summary of virus data represented after downsampling:**

```{r}
model_df %>% 
   dplyr::count(childtaxa_name, outcome) %>% 
   spread(outcome, n, fill = 0) %>% 
   mutate(total = rowSums(select_(., "-childtaxa_name"))) %>% 
   arrange(-total) %>%
   filter(total >= 10) %>%
   kable(caption = "CoV spike sequences, host groups/sequences represented per CoV species after downsampling")
```

MERS/SARS and the livestock/companion animal CoVs overrepresented, so now downsampled to max 20 sequences per outcome. All other CoVs _(`r model_df %>% dplyr::count(childtaxa_name) %>% filter(n<10) %>% nrow`)_ have < 10 sequences.

```{r plot_mers_seqs, results="asis", layout="l-screen-inset", fig.height=6.0, fig.width=8.0}
# ggplot(model_df %>% 
#           filter(childtaxa_name == "Middle East respiratory syndrome-related coronavirus") %>% 
#           filter(outcome != "yangbat") %>%
#           select(outcome, matches("^[A|C|G|T][A|C|G|T][A|C|G|T]_Bias$")) %>% melt(id.vars = "outcome"), 
#        aes(y = value, x = outcome, fill = outcome)) +  
#    geom_boxplot(outlier.size=0.8) +
#    facet_wrap(. ~ variable, scales="free_y") +
#    theme_bw(base_size = 8) +
#    theme(axis.text.x=element_blank()) +
#    xlab("") +
#    ylab("Codon bias")
```

**ML options:**
Use stop codons set to _`r use_stop_codons`_.

**Parameters from grid search, RF**:
```{r rf_gridsearch, results="asis", layout="l-screen-inset", fig.height=4.0, fig.width=6.0}
gridsearch <- lapply(rf_list, function(x)
   x$results
) %>% bind_rows() %>% mutate(min.node.size = factor(min.node.size, levels = c("5", "12.5", "20")),
                             mtry = factor(mtry, levels = c("5", "12.5", "20")))

p1 <- ggplot(gridsearch, aes(y = Accuracy, x = min.node.size, fill = mtry)) +
   geom_boxplot() +
   theme_bw() +
   ylab("Cross-validation (inner loop) accuracy")

bestparams <- lapply(rf_list, function(x)
   x$results %>% arrange(-Accuracy) %>% slice(1)
) %>% bind_rows() %>% mutate(min.node.size = factor(min.node.size, levels = c("5", "12.5", "20")),
                             mtry = factor(mtry, levels = c("5", "12.5", "20")))

p2 <- bestparams %>% 
   group_by(min.node.size, mtry) %>%
   dplyr::count() %>%
   ggplot(aes(x=min.node.size, y=mtry, fill=n)) +
   geom_tile() +
   scale_fill_distiller(palette="RdYlBu", direction=1) +
   labs(fill = "n selections") +
   theme_bw()

p1 + p2 + plot_layout(widths = c(2.5, 1))
```

_Low nodesize best, but accuracy relatively indifferent to mtry_

**Confusion matrices, multiclass AUC on outer loop:**
```{r}
predict_class_test <- Map(function(model, newdata)
   predict(model, newdata=newdata, type="raw"),
   model = rf_list,
   newdata = holdout_used
) %>% unlist

predict_prob_test <- Map(function(model, newdata)
   predict(model, newdata=newdata, type="prob"),
   model = rf_list,
   newdata = holdout_used
) %>% bind_rows

matrix_test <- confusionMatrix(predict_class_test, holdout_used %>% bind_rows %>% pull(outcome) %>% droplevels)

matrix_test$overall %>% round(., 3) %>% t %>%
   kable(caption = "Diagnostics")
matrix_test$table %>%
   kable(caption = "Confusion matrix")

multiclass.roc(response = holdout_used %>% bind_rows %>% pull(outcome), predictor = predict_prob_test) %>% .$auc %>% as.numeric %>% print
```

**Misclassified sequences:**
```{r}
holdout_used %>%
   bind_rows() %>%
   add_column(predict = predict_class_test) %>%
   filter(as.character(outcome) != as.character(predict)) %>%
   select(childtaxa_name, accessionversion, outcome, predict)
```

**Variable importance (RF only):**
```{r varimp, results="asis", layout="l-body-outset", fig.height=6.0, fig.width=8.0}
varimp <- lapply(rf_list, function(x)
   varImp(x)$importance %>% rownames_to_column("name") %>% mutate(Overall = Overall/100) %>% rename(relGini = Overall)
) %>% bind_rows()

varimp_order <- varimp %>%                               
   group_by(name) %>% 
   summarise(mean = mean(relGini)) %>% 
   mutate(name = fct_reorder(name, -mean)) %>% 
   pull(name) %>% 
   levels

ggplot(varimp %>%
          mutate(name = factor(name, levels = varimp_order),
                 type = case_when(grepl("^[A|C|G|T]_Bias$", name) ~ "nucs",
                                  grepl("^[A|C|G|T][A|C|G|T]_p[1|2|3]_Bias", name) ~ "dinucs",
                                  grepl("^[A|C|G|T][A|C|G|T][A|C|G|T]_Bias$", name) ~ "codons")) %>%
          filter(name %in% varimp_order[1:30]), 
       aes(x=name, y=relGini, fill=type)) +
   stat_summary(geom = "bar", fun.y = "mean") +
   stat_summary(geom = "errorbar", fun.data=mean_sdl, fun.args=list(mult=1), lwd=0.25, width=0) +
   coord_flip(ylim=c(0,1.02), expand=FALSE) + 
   scale_y_continuous(breaks=seq(0,1,0.1)) +
   theme_bw(base_size = 11) + xlab("Predictor variable") + ylab("Relative importance") +
   ggtitle("Variable importance, top 30 predictors") +
   theme(legend.justification=c(1,1), legend.position=c(.98,.35), panel.spacing = unit(1.1, "lines")) +
   scale_fill_manual(values=cbbPalette, name = "Predictor type")
```

Mixed, though few nucleotides. STOP codons rank at _`r varimp %>% group_by(name) %>% summarise(mean = mean(relGini)) %>% mutate(r = 1:length(varimp_order)) %>% filter(name %in% c("TGA_Bias", "TAG_Bias", "TAA_Bias")) %>% pull(r)`_ of _`r length(varimp_order)`_ variables - not as informative considering multiple host categories (or sequence host metadata) cf.PCAs of human:nonhuman virus spp.

**Spike-wgs comparison:**
```{r varimp_corr, results="asis", layout="l-body-outset", fig.height=10.0, fig.width=10.0}
varimp_spike <- readRDS("varimp_spike.rds")

varimp_comp <- varimp %>%                            
   group_by(name) %>% 
   summarise(mean_wgs = mean(relGini)) %>%
   left_join(varimp_spike %>%
                group_by(name) %>% 
                summarise(mean_spike = mean(relGini)),
             by = "name") %>%
          mutate(type = case_when(grepl("^[A|C|G|T]_Bias$", name) ~ "nucs",
                                  grepl("^[A|C|G|T][A|C|G|T]_p[1|2|3]_Bias", name) ~ "dinucs",
                                  grepl("^[A|C|G|T][A|C|G|T][A|C|G|T]_Bias$", name) ~ "codons"))

ggplot(varimp_comp,
       aes(x = mean_wgs, y = mean_spike, colour=type)) +
   geom_point(size = 4, alpha = 0.5) +
   scale_colour_manual(values=cbbPalette, name = "Predictor type") +
   xlab("mean relative variable importance, whole genome sequences") +
   ylab("mean relative variable importance, spike proteins") +
   annotate("text", x = 0.9, y = 0.9, label = paste0("r = ",round(cor(varimp_comp$mean_wgs, varimp_comp$mean_spike, method = "spearman"),3))) +
   theme_bw()

```

Very different importances between the spike protein and the whole genome....

**Partial dependence (RF only):**
```{r include=FALSE}

# Load in stored PD
load("C:\\Users\\Liam\\Desktop\\CoV Genomics\\listresults_pd_wg_21_07_20.RData")

vars_to_pd <- varimp_order[1:5]

for (i in 1:length(vars_to_pd)){
   
   plot_df <- lapply(list_PD, function(x) x[[vars_to_pd[i]]]) %>% bind_rows
   
   #plot_df[,2:ncol(plot_df)] <- (plot_df[,2:ncol(plot_df)]/(1-plot_df[,2:ncol(plot_df)])) %>% mapply('/', ., (vector_probs/(1-vector_probs))) # calculate odds ratios
   
   assign(paste0("p_", i), ggplot(plot_df %>% melt(id.vars = vars_to_pd[i]), 
                                  aes(x = !!sym(vars_to_pd[i]), y = value, color = variable, fill = variable)) +  
             stat_summary(geom="ribbon", fun.data=
                             #                          mean_cl_normal, 
                             #                          mean_cl_boot, 
                             median_hilow,
                          fun.args=list(conf.int=0.95), alpha = 0.2,  colour = NA) +
             stat_summary(geom="line", fun=mean, lwd = 1.5, alpha = 0.8) +
             #geom_hline(yintercept=1, alpha = 0.3, color="grey50", lty="dashed", size=1) +
             scale_color_manual(values=cbbPalette_full, name = "host") +
             scale_fill_manual(values=cbbPalette_full, name = "host") +
             ylab("probability") +
             guides(color = FALSE, fill = FALSE) +
             facet_wrap(~ variable) +
             theme_bw())
}
```

```{r pd, results="asis", layout="l-screen-inset", fig.height=10.0, fig.width=15.0}

wrap_plots(p_1, p_2, p_3, p_4, p_5)

```

Plotted as median, with shading denoting upper/lower quartile (bootstrap or normal 95% CI show basically no variance).